import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
import os
import cv2
import tempfile

# 1. C·∫•u h√¨nh giao di·ªán
st.set_page_config(page_title="AI Vision Pro", layout="centered")

st.markdown("<h2 style='text-align: center;'>ü§ñ Nh·∫≠n di·ªán ·∫¢nh & Video AI</h2>", unsafe_allow_html=True)

# 2. ƒê∆∞·ªùng d·∫´n m√¥ h√¨nh (File n·∫±m c√πng th∆∞ m·ª•c v·ªõi app.py)
MODEL_PATH = "MobileNetV2.keras"

@st.cache_resource
def load_model_ai():
    if not os.path.exists(MODEL_PATH):
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file {MODEL_PATH} tr√™n GitHub!")
        return None
    try:
        # S·ª≠ d·ª•ng tf.keras ƒë·ªÉ load (C√°ch an to√†n nh·∫•t cho b·∫£n 2.15)
        model = tf.keras.models.load_model(MODEL_PATH, compile=False)
        return model
    except Exception as e:
        st.error(f"‚ùå L·ªói n·∫°p m√¥ h√¨nh: {e}")
        return None

model = load_model_ai()

# 3. Giao di·ªán t·∫£i file
uploaded_file = st.file_uploader("T·∫£i ·∫¢nh ho·∫∑c Video", type=["jpg", "png", "jpeg", "mp4", "mov"])

if uploaded_file and model:
    # Ph√¢n lo·∫°i file
    is_video = uploaded_file.type.startswith('video')

    if not is_video:
        # --- X·ª¨ L√ù ·∫¢NH ---
        img = Image.open(uploaded_file).convert('RGB')
        st.image(img, use_container_width=True)
        
        if st.button("üîç B·∫Øt ƒë·∫ßu ph√¢n t√≠ch ·∫¢nh"):
            # Ti·ªÅn x·ª≠ l√Ω (224x224 cho MobileNetV2)
            img_prep = np.array(img.resize((224, 224)))
            img_prep = tf.keras.applications.mobilenet_v2.preprocess_input(np.expand_dims(img_prep, axis=0))
            
            preds = model.predict(img_prep)
            st.success(f"### D·ª± ƒëo√°n: Nh√£n {np.argmax(preds)}")
            st.info(f"ƒê·ªô tin c·∫≠y: {np.max(preds)*100:.2f}%")

    else:
        # --- X·ª¨ L√ù VIDEO ---
        st.video(uploaded_file)
        if st.button("‚ñ∂Ô∏è Ph√¢n t√≠ch Video"):
            with st.spinner("ƒêang tr√≠ch xu·∫•t khung h√¨nh..."):
                t_file = tempfile.NamedTemporaryFile(delete=False)
                t_file.write(uploaded_file.read())
                
                cap = cv2.VideoCapture(t_file.name)
                # L·∫•y khung h√¨nh t·∫°i gi√¢y ƒë·∫ßu ti√™n
                cap.set(cv2.CAP_PROP_POS_MSEC, 1000)
                ret, frame = cap.read()
                
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    img_prep = np.array(Image.fromarray(frame_rgb).resize((224, 224)))
                    img_prep = tf.keras.applications.mobilenet_v2.preprocess_input(np.expand_dims(img_prep, axis=0))
                    
                    preds = model.predict(img_prep)
                    st.success(f"### D·ª± ƒëo√°n Video: Nh√£n {np.argmax(preds)}")
                else:
                    st.error("Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh video.")
                cap.release()
                os.unlink(t_file.name)
