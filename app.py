import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
import os
import cv2
import tempfile

# C·∫•u h√¨nh giao di·ªán
st.set_page_config(page_title="AI Vision Pro", page_icon="ü§ñ", layout="centered")

# CSS t√πy ch·ªânh ƒë·ªÉ l√†m ƒë·∫πp giao di·ªán
st.markdown("""
    <style>
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] { height: 50px; border-radius: 5px; background-color: #f0f2f6; }
    .stMetric { background-color: #ffffff; padding: 10px; border-radius: 10px; border: 1px solid #e6e9ef; }
    </style>
    """, unsafe_allow_html=True)

st.title("ü§ñ Tr√≠ tu·ªá Nh√¢n t·∫°o Nh·∫≠n di·ªán ·∫¢nh & Video")
st.info("H·ªá th·ªëng ƒëang ch·∫°y tr√™n m√¥i tr∆∞·ªùng Python 3.11 & TensorFlow 2.15")

# --- QU·∫¢N L√ù M√î H√åNH ---
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "MobileNetV2.keras")

@st.cache_resource
def load_model_ai():
    if not os.path.exists(MODEL_PATH):
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh t·∫°i th∆∞ m·ª•c g·ªëc!")
        return None
    try:
        # Load m√¥ h√¨nh b·∫±ng tf.keras ƒë·ªÉ tr√°nh l·ªói c·∫•u tr√∫c Layer tr√™n m√¥i tr∆∞·ªùng m·ªõi
        return tf.keras.models.load_model(MODEL_PATH, compile=False)
    except Exception as e:
        st.error(f"‚ùå L·ªói n·∫°p m√¥ h√¨nh: {str(e)}")
        return None

model = load_model_ai()

# --- X·ª¨ L√ù D·ªÆ LI·ªÜU ---
def preprocess(image):
    img = image.resize((224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    return tf.keras.applications.mobilenet_v2.preprocess_input(img_array)

if model:
    tab1, tab2 = st.tabs(["üñºÔ∏è Nh·∫≠n di·ªán ·∫¢nh", "üé• Nh·∫≠n di·ªán Video"])

    with tab1:
        file_img = st.file_uploader("Ch·ªçn ·∫£nh (JPG, PNG)...", type=["jpg", "png", "jpeg"])
        if file_img:
            img = Image.open(file_img).convert('RGB')
            st.image(img, use_container_width=True)
            if st.button("üöÄ Ph√¢n t√≠ch ·∫¢nh"):
                processed = preprocess(img)
                preds = model.predict(processed)
                label = np.argmax(preds)
                conf = np.max(preds) * 100
                
                col1, col2 = st.columns(2)
                col1.metric("Nh√£n d·ª± ƒëo√°n", f"S·ªë {label}")
                col2.metric("ƒê·ªô tin c·∫≠y", f"{conf:.2f}%")

    with tab2:
        file_vid = st.file_uploader("Ch·ªçn video (MP4, MOV)...", type=["mp4", "mov"])
        if file_vid:
            st.video(file_vid)
            if st.button("‚ñ∂Ô∏è Ph√¢n t√≠ch Video"):
                with st.spinner("ƒêang tr√≠ch xu·∫•t khung h√¨nh..."):
                    t_file = tempfile.NamedTemporaryFile(delete=False)
                    t_file.write(file_vid.read())
                    cap = cv2.VideoCapture(t_file.name)
                    cap.set(cv2.CAP_PROP_POS_MSEC, 1000) # L·∫•y d·ªØ li·ªáu t·∫°i gi√¢y th·ª© 1
                    ret, frame = cap.read()
                    if ret:
                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        processed = preprocess(Image.fromarray(frame_rgb))
                        preds = model.predict(processed)
                        st.success(f"K·∫øt qu·∫£ Video: Nh√£n {np.argmax(preds)}")
                    cap.release()
                    os.unlink(t_file.name)

st.divider()
st.caption("Thi·∫øt k·∫ø b·ªüi Gemini AI - 2026")
