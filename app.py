import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
import os
import cv2
import tempfile

# Giao di·ªán
st.set_page_config(page_title="AI Classifier", layout="centered")
st.title("ü§ñ Nh·∫≠n di·ªán ·∫¢nh & Video AI")

# ƒê∆∞·ªùng d·∫´n file m√¥ h√¨nh ngay t·∫°i th∆∞ m·ª•c g·ªëc
MODEL_PATH = "MobileNetV2.keras"

@st.cache_resource
def load_model_fixed():
    if not os.path.exists(MODEL_PATH):
        st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file {MODEL_PATH} tr√™n GitHub c·ªßa b·∫°n!")
        return None
    try:
        # Load m√¥ h√¨nh v√† kh√¥ng bi√™n d·ªãch (compile=False) ƒë·ªÉ tr√°nh l·ªói phi√™n b·∫£n
        model = tf.keras.models.load_model(MODEL_PATH, compile=False)
        return model
    except Exception as e:
        st.error(f"‚ùå L·ªói load m√¥ h√¨nh: {e}")
        return None

model = load_model_fixed()

# Ch·ª©c nƒÉng d·ª± ƒëo√°n chung
def predict_logic(img_pil):
    # MobileNetV2 chu·∫©n: 224x224
    img_resized = img_pil.resize((224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img_resized)
    img_array = np.expand_dims(img_array, axis=0)
    img_final = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
    
    prediction = model.predict(img_final)
    return np.argmax(prediction), np.max(prediction) * 100

# Giao di·ªán t·∫£i file
file = st.file_uploader("T·∫£i l√™n ·∫¢nh ho·∫∑c Video", type=["jpg", "png", "jpeg", "mp4", "mov"])

if file and model:
    is_video = file.type.startswith('video')
    
    if not is_video:
        # X·ª¨ L√ù ·∫¢NH
        image = Image.open(file).convert('RGB')
        st.image(image, use_container_width=True)
        if st.button("üîç D·ª± ƒëo√°n ·∫¢nh"):
            label, conf = predict_logic(image)
            st.success(f"K·∫øt qu·∫£: Nh√£n {label} (ƒê·ªô tin c·∫≠y: {conf:.2f}%)")
    else:
        # X·ª¨ L√ù VIDEO
        st.video(file)
        if st.button("‚ñ∂Ô∏è D·ª± ƒëo√°n Video"):
            with st.spinner("ƒêang ph√¢n t√≠ch khung h√¨nh..."):
                t_file = tempfile.NamedTemporaryFile(delete=False)
                t_file.write(file.read())
                cap = cv2.VideoCapture(t_file.name)
                cap.set(cv2.CAP_PROP_POS_MSEC, 1000) # L·∫•y t·∫°i gi√¢y th·ª© 1
                ret, frame = cap.read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    label, conf = predict_logic(Image.fromarray(frame_rgb))
                    st.success(f"K·∫øt qu·∫£ Video: Nh√£n {label}")
                cap.release()
                os.unlink(t_file.name)
