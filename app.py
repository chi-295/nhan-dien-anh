import streamlit as st
import tensorflow as tf
import numpy as np
from PIL import Image
import os
import cv2
import tempfile

# C·∫•u h√¨nh trang
st.set_page_config(page_title="AI Recognition", layout="centered")
st.title("üöÄ Ph·∫ßn m·ªÅm nh·∫≠n di·ªán ·∫¢nh & Video AI")

# --- S·ª¨A ƒê∆Ø·ªúNG D·∫™N: File n·∫±m ngay th∆∞ m·ª•c g·ªëc ---
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "MobileNetV2.keras") # Kh√¥ng c√≤n ch·ªØ 'model/' ·ªü tr∆∞·ªõc

@st.cache_resource
def load_model_safe():
    if not os.path.exists(MODEL_PATH):
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {MODEL_PATH}")
        st.write("C√°c file hi·ªán c√≥ tr√™n GitHub c·ªßa b·∫°n:", os.listdir(BASE_DIR))
        return None
    try:
        return tf.keras.models.load_model(MODEL_PATH, compile=False)
    except Exception as e:
        st.error(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
        return None

model = load_model_safe()

# --- GIAO DI·ªÜN CH∆Ø∆†NG TR√åNH ---
uploaded_file = st.file_uploader("T·∫£i ·∫¢nh ho·∫∑c Video v√†o ƒë√¢y", type=["jpg", "png", "jpeg", "mp4", "mov"])

if uploaded_file and model:
    # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
    is_video = uploaded_file.type.startswith('video')
    
    if not is_video:
        # X·ª¨ L√ù ·∫¢NH
        img = Image.open(uploaded_file).convert('RGB')
        st.image(img, width=300, caption="·∫¢nh ƒë√£ t·∫£i l√™n")
        
        if st.button("üîç D·ª± ƒëo√°n ·∫¢nh"):
            # Ti·ªÅn x·ª≠ l√Ω cho MobileNetV2 (224x224)
            img_input = np.array(img.resize((224, 224)))
            img_input = tf.keras.applications.mobilenet_v2.preprocess_input(np.expand_dims(img_input, axis=0))
            
            pred = model.predict(img_input)
            st.success(f"K·∫øt qu·∫£ nh√£n: **{np.argmax(pred)}** (Tin c·∫≠y: {np.max(pred)*100:.2f}%)")

    else:
        # X·ª¨ L√ù VIDEO
        st.video(uploaded_file)
        if st.button("‚ñ∂Ô∏è Ph√¢n t√≠ch Video"):
            with st.spinner("ƒêang x·ª≠ l√Ω..."):
                t_file = tempfile.NamedTemporaryFile(delete=False) 
                t_file.write(uploaded_file.read())
                
                cap = cv2.VideoCapture(t_file.name)
                cap.set(cv2.CAP_PROP_POS_MSEC, 1000) # L·∫•y khung h√¨nh ·ªü gi√¢y th·ª© 1
                ret, frame = cap.read()
                
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    img_input = np.array(Image.fromarray(frame_rgb).resize((224, 224)))
                    img_input = tf.keras.applications.mobilenet_v2.preprocess_input(np.expand_dims(img_input, axis=0))
                    
                    pred = model.predict(img_input)
                    st.success(f"K·∫øt qu·∫£ video (khung h√¨nh ch√≠nh): **{np.argmax(pred)}**")
                else:
                    st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c video.")
                
                cap.release()
                os.unlink(t_file.name)
